# Pre-sales & Discovery Phase Activities
## PowerPoint Presentation Content

---

## ğŸ¯ PRE-SALES PHASE
### Duration: 1-2 weeks

### **Week 1: Opportunity Qualification**

#### **Activity 1: Initial Assessment**
- Understand client's business problem
- Identify pain points and impact
- Assess urgency and timeline
- Evaluate budget and resources

#### **Activity 2: Business Value Analysis**
- Quantify potential benefits (cost savings, revenue uplift)
- Calculate estimated ROI
- Assess strategic alignment
- Identify business drivers

#### **Activity 3: Technical Feasibility Check**
- Determine if problem is suitable for AI/ML
- Identify ML problem type (classification, regression, NLP, etc.)
- Assess technical complexity
- Evaluate integration requirements

#### **Activity 4: Data Quick Assessment**
- Identify potential data sources
- Estimate data volume and availability
- Check data access feasibility
- Flag potential data quality concerns

#### **Activity 5: Client Readiness Evaluation**
- Assess AI maturity level
- Evaluate stakeholder engagement
- Review team capabilities
- Check organizational readiness for change

#### **Activity 6: Qualification Scoring**
- Score across 5 dimensions (50-point scale):
  - Business Value (30%)
  - Technical Feasibility (25%)
  - Data Readiness (20%)
  - Client Readiness (15%)
  - Commercial Viability (10%)
- Make Go/No-Go decision

**Deliverable**: Opportunity Qualification Report with Go/No-Go recommendation

---

## ğŸ” DISCOVERY PHASE
### Duration: 2-4 weeks

### **Week 1: Business Requirements & Use Cases**

#### **Activity 1: Business Requirements Workshop Preparation**
- Define workshop objectives
- Identify and invite stakeholders
- Prepare workshop materials
- Schedule sessions (4+ hours)

#### **Activity 2: Current State Assessment Workshop**
- Map current business processes
- Document pain points and challenges
- Capture quantitative metrics (time, cost, volume, errors)
- Identify constraints and limitations
- Gather stakeholder perspectives

#### **Activity 3: Future State Definition Workshop**
- Envision desired future state
- Clarify business objectives
- Define success criteria
- Create user personas
- Identify key scenarios

#### **Activity 4: Use Case Identification & Prioritization**
- List all potential AI use cases
- Describe each use case (problem, solution, benefit)
- Assess business value and technical feasibility
- Prioritize using scoring matrix
- Select MVP use cases (2-3)

#### **Activity 5: Detailed Requirements Documentation**
- Write functional requirements
- Define non-functional requirements (performance, security, compliance)
- Specify data requirements
- Document integration requirements
- Create user stories with acceptance criteria

#### **Activity 6: Requirements Review & Sign-off**
- Business Owner review
- Technical team review
- Compliance/Legal review
- Incorporate feedback
- Obtain formal sign-off

**Deliverables**: Business Requirements Document (BRD), Use Case Specifications

---

### **Week 2: Data Discovery & Assessment**

#### **Activity 7: Data Source Identification**
- Create data source inventory
- Identify data owners
- Document data locations and formats
- Understand refresh frequencies

#### **Activity 8: Data Access & Exploration**
- Submit data access requests
- Obtain sample datasets
- Set up data exploration environment
- Initial data profiling

#### **Activity 9: Data Quality Assessment**
- Assess completeness (missing values)
- Evaluate accuracy (validation rules, ranges)
- Check consistency (formats, naming)
- Measure timeliness (freshness, lag)
- Validate business rules
- Detect duplicates
- Generate data quality scorecard

#### **Activity 10: Data Volume & Distribution Analysis**
- Analyze total record counts and growth trends
- Examine feature distributions
- Assess class balance (for classification)
- Identify outliers
- Determine data sufficiency for ML

#### **Activity 11: Privacy & Compliance Assessment**
- Identify Personal Data (PII)
- Classify data sensitivity
- Assess GDPR/regulatory requirements
- Conduct Data Privacy Impact Assessment (DPIA)
- Define privacy controls and anonymization needs

**Deliverables**: Data Assessment Report, Data Quality Scorecard, DPIA

---

### **Week 3: AI/ML Approach Design**

#### **Activity 12: ML Problem Framing**
- Define ML problem type (classification, regression, NLP, etc.)
- Specify input features and output predictions
- Define success metrics (accuracy, precision, recall, etc.)
- Establish baseline performance

#### **Activity 13: Algorithm & Approach Selection**
- Identify algorithm candidates (traditional ML, deep learning, pre-trained models)
- Evaluate approaches (accuracy potential, training requirements, complexity)
- Select Azure AI services (Azure ML, Cognitive Services, OpenAI)
- Document trade-offs and rationale

#### **Activity 14: Feature Engineering Strategy**
- Identify raw features from data sources
- Plan derived features (aggregations, ratios, temporal)
- Define categorical encoding approach
- Design feature selection strategy

#### **Activity 15: Model Training & Evaluation Strategy**
- Define train/validation/test split
- Plan cross-validation approach
- Design hyperparameter tuning strategy
- Define evaluation metrics and thresholds
- Plan fairness and bias assessment

**Deliverables**: ML Approach Document, Feature Engineering Plan

---

### **Week 3-4: Solution Architecture**

#### **Activity 16: High-Level Architecture Design**
- Design end-to-end architecture (data â†’ model â†’ application)
- Map components to Azure services
- Create architecture diagrams
- Define data flow

#### **Activity 17: Data Architecture Design**
- Design data pipelines (ingestion, transformation, validation)
- Plan data storage strategy (Data Lake, databases)
- Define data governance approach
- Document data lineage

#### **Activity 18: ML Architecture Design**
- Design training pipeline
- Plan model serving approach (real-time, batch)
- Define MLOps strategy (CI/CD, monitoring, retraining)
- Design A/B testing framework

#### **Activity 19: Integration Architecture**
- Design API specifications
- Plan integration patterns (REST, events, messaging)
- Define authentication/authorization approach
- Document error handling strategy

#### **Activity 20: Security Architecture**
- Design identity and access management (Azure AD, RBAC)
- Plan encryption strategy (at rest, in transit)
- Define network security (NSGs, firewalls, private endpoints)
- Design audit logging and compliance controls

#### **Activity 21: Monitoring & Observability**
- Define monitoring strategy (Application Insights, Azure Monitor)
- Plan alerting approach
- Design dashboards (operational, business metrics)
- Define logging strategy

**Deliverables**: Solution Architecture Document, Architecture Diagrams

---

### **Week 4: Validation & Planning**

#### **Activity 22: Proof of Concept (Optional but Recommended)**
- Define POC objectives
- Prepare sample data
- Build quick baseline model
- Validate technical approach
- Document POC results

#### **Activity 23: Technical Feasibility Validation**
- Confirm data sufficiency
- Validate model accuracy is achievable
- Verify performance requirements are realistic
- Assess integration complexity
- Validate cost estimates

#### **Activity 24: Solution Design Reviews**
- Internal technical review
- Architecture review
- Security review
- Business Owner review
- Executive briefing

#### **Activity 25: Prototype Phase Planning**
- Define MVP scope
- Plan sprints (typically 3-4 x 2-week sprints)
- Create sprint backlog
- Estimate effort and velocity
- Confirm resource allocation

#### **Activity 26: Discovery Documentation**
- Compile Discovery Report (executive summary)
- Finalize all supporting documents
- Create phase gate presentation
- Prepare for steering committee review

#### **Activity 27: Discovery Phase Gate Review**
- Present findings to steering committee
- Review all deliverables and sign-offs
- Assess exit criteria
- Obtain Go/No-Go decision for Prototype phase

**Deliverables**: Discovery Report, POC Results (if conducted), Prototype Plan, Phase Gate Approval

---

## ğŸ“Š KEY DELIVERABLES SUMMARY

### **Pre-sales Deliverables**
1. âœ… Opportunity Qualification Report
2. âœ… Go/No-Go Decision with rationale

### **Discovery Deliverables**
1. âœ… Business Requirements Document (BRD)
2. âœ… Use Case Specifications
3. âœ… Data Assessment Report
4. âœ… Data Quality Scorecard
5. âœ… Data Privacy Impact Assessment (DPIA)
6. âœ… ML Approach Document
7. âœ… Feature Engineering Plan
8. âœ… Solution Architecture Document
9. âœ… Architecture Diagrams
10. âœ… POC Results (if conducted)
11. âœ… Discovery Report
12. âœ… Prototype Plan
13. âœ… Risk Register (updated)
14. âœ… Phase Gate Approval

---

## ğŸ¯ SUCCESS CRITERIA

### **Pre-sales Exit Criteria**
- [ ] Opportunity scored >6.0/10.0 (weighted)
- [ ] Business value clearly quantified
- [ ] Technical feasibility confirmed
- [ ] Go decision with executive sponsorship

### **Discovery Exit Criteria**
- [ ] Business requirements documented and approved
- [ ] Data sources identified and accessed
- [ ] Data quality assessed (>80% completeness, <5% error rate)
- [ ] Data volume sufficient for ML (typically >10K records)
- [ ] Privacy/compliance approved (DPIA complete)
- [ ] AI/ML approach defined and validated
- [ ] Solution architecture approved by CIO/CTO
- [ ] Technical feasibility confirmed (POC successful if conducted)
- [ ] No blocking technical risks
- [ ] Prototype plan created
- [ ] Stakeholder alignment achieved
- [ ] Phase gate approval obtained

---

## ğŸ“ˆ TYPICAL TIMELINES

| Phase | Duration | Effort (Person-Days) |
|-------|----------|---------------------|
| **Pre-sales** | 1-2 weeks | 5-10 days |
| **Discovery** | 2-4 weeks | 20-40 days |
| **Total** | 3-6 weeks | 25-50 days |

---

## ğŸ‘¥ KEY ROLES INVOLVED

### **Pre-sales**
- Account Executive
- Solution Architect
- AI/ML Specialist
- Data Consultant

### **Discovery**
- Business Analyst / Product Owner
- AI/ML Lead / Data Scientist
- Solution Architect
- Data Engineer
- Security Architect
- Business Stakeholders (SMEs, end users)
- Executive Sponsor

---

## ğŸ¨ POWERPOINT SLIDE SUGGESTIONS

### **Slide 1: Phase Overview**
- Title: "Pre-sales & Discovery: Foundation for Success"
- Duration: 3-6 weeks
- Purpose: Qualify opportunity and validate feasibility
- Key outcome: Go/No-Go with validated solution design

### **Slide 2: Pre-sales Activities (Week 1-2)**
- 6 key activities in visual workflow
- Input â†’ Assessment â†’ Scoring â†’ Decision
- Deliverable: Qualification Report

### **Slide 3: Discovery Week 1 - Business Requirements**
- Workshop approach (Current State â†’ Future State)
- Use case prioritization matrix
- Deliverable: BRD with use cases

### **Slide 4: Discovery Week 2 - Data Assessment**
- Data discovery flow diagram
- 6 data quality dimensions
- Deliverable: Data Assessment Report

### **Slide 5: Discovery Week 3 - AI/ML Design**
- Problem framing â†’ Algorithm selection â†’ Feature engineering
- Azure services mapping
- Deliverable: ML Approach Document

### **Slide 6: Discovery Week 3-4 - Architecture**
- End-to-end architecture diagram
- Components: Data â†’ ML â†’ Application â†’ Integration
- Deliverable: Solution Architecture

### **Slide 7: Discovery Week 4 - Validation**
- POC results (if conducted)
- Design reviews completed
- Phase gate criteria checklist
- Deliverable: Discovery Report & Approval

### **Slide 8: Key Deliverables**
- Visual checklist of 14 deliverables
- Icons for each deliverable type
- Progress tracker

### **Slide 9: Success Metrics**
- Business value quantified: Â£X savings, Y% improvement
- Data quality score: 85%+
- Technical feasibility: Confirmed with POC
- Stakeholder alignment: 100% sign-off

### **Slide 10: Phase Gate Decision**
- Exit criteria met/not met
- Risk summary (with mitigation)
- Recommendation: GO / CONDITIONAL GO / NO GO
- Next phase: Prototype kickoff date

---

## ğŸ’¡ TIPS FOR PRESENTATIONS

### **Visual Elements to Include**
- ğŸ”„ **Process Flow Diagrams** - Show activity sequence
- ğŸ“Š **Scoring Matrices** - For qualification and prioritization
- ğŸ“ˆ **Data Quality Dashboards** - Visual scorecard
- ğŸ—ï¸ **Architecture Diagrams** - High-level and detailed
- âœ… **Checklist Trackers** - Show progress and completeness
- ğŸ¯ **RACI Charts** - Show who does what
- ğŸ“… **Timeline Gantt Charts** - Show weekly activities

### **Key Messages to Emphasize**
1. **Risk Reduction**: Discovery de-risks the project before heavy investment
2. **Data is Critical**: 80% of AI success depends on data quality
3. **Stakeholder Alignment**: Early engagement prevents later issues
4. **Iterative Validation**: POC proves feasibility before commitment
5. **Governance**: Phase gates ensure quality and alignment

### **Common Objections & Responses**
- **"Discovery takes too long"** â†’ "3-4 weeks now saves 3-4 months later by preventing false starts"
- **"Can't we skip this?"** â†’ "70% of AI projects fail due to poor requirements and data quality"
- **"Just start building"** â†’ "Without discovery, we risk building the wrong solution on the wrong data"

---

## ğŸ“‹ ACTIVITY CHECKLIST FORMAT

Use this format for PowerPoint checklist slides:

**Pre-sales Activities** (1-2 weeks)
- â˜ Initial Assessment
- â˜ Business Value Analysis  
- â˜ Technical Feasibility Check
- â˜ Data Quick Assessment
- â˜ Client Readiness Evaluation
- â˜ Qualification Scoring & Go/No-Go

**Discovery Week 1: Business Requirements**
- â˜ Requirements Workshop Prep
- â˜ Current State Assessment
- â˜ Future State Definition
- â˜ Use Case Identification & Prioritization
- â˜ Requirements Documentation
- â˜ Requirements Sign-off

**Discovery Week 2: Data Assessment**
- â˜ Data Source Identification
- â˜ Data Access & Exploration
- â˜ Data Quality Assessment (6 dimensions)
- â˜ Volume & Distribution Analysis
- â˜ Privacy & Compliance Assessment

**Discovery Week 3: AI/ML Design**
- â˜ ML Problem Framing
- â˜ Algorithm & Approach Selection
- â˜ Feature Engineering Strategy
- â˜ Training & Evaluation Strategy

**Discovery Week 3-4: Architecture**
- â˜ High-Level Architecture
- â˜ Data Architecture
- â˜ ML Architecture & MLOps
- â˜ Integration Architecture
- â˜ Security Architecture
- â˜ Monitoring & Observability

**Discovery Week 4: Validation**
- â˜ Proof of Concept (optional)
- â˜ Feasibility Validation
- â˜ Design Reviews
- â˜ Prototype Planning
- â˜ Discovery Documentation
- â˜ Phase Gate Review

---

## ğŸ¯ ONE-PAGE SUMMARY FOR EXECUTIVES

**Pre-sales & Discovery: 3-6 Weeks to De-Risk Your AI Investment**

**Why It Matters:**
- 70% of AI projects fail due to poor planning and data issues
- Discovery validates feasibility BEFORE major investment
- Clear requirements prevent costly rework

**What We Do:**
1. **Qualify** the opportunity (1-2 weeks)
2. **Understand** business needs & use cases (Week 1)
3. **Assess** data quality & availability (Week 2)
4. **Design** AI/ML approach & architecture (Week 3-4)
5. **Validate** with POC and reviews (Week 4)

**What You Get:**
- âœ… Go/No-Go decision based on facts, not assumptions
- âœ… Validated solution design with Azure architecture
- âœ… Clear requirements and success criteria
- âœ… Data quality assessment and remediation plan
- âœ… Risk identification and mitigation strategies
- âœ… Accurate cost and timeline estimates for delivery

**Investment:** 25-50 person-days over 3-6 weeks

**ROI:** Prevents 3-6 months of wasted effort and Â£200K-500K in failed projects

**Decision Point:** Phase Gate Review with Steering Committee

---

**End of Presentation Guide**
